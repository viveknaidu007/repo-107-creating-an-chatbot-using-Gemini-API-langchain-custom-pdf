# repo-107-creating-an-system-using-Openai-API-or-Gemini-API-on-custom-text-document
here im bulding an own ai model using LLM apis to give answer for the user query

## steps:
* create an .env file and paste ur gemini api key (its a good process of using api keys)
* here i was taken gemini api key as it was free now
* install libraries ot run the code
* check the custom pdf to train
* query the result


## Gemini is a variant of the GPT (Generative Pre-trained Transformer) model, which is based on the Transformer architecture. These models, including Gemini, are pre-trained using unsupervised learning on large text corpora, enabling them to understand the semantics and context of the text.

## When you input text to a model like Gemini, it processes the text through its layers, which include attention mechanisms and self-attention layers. These layers allow the model to capture the context and relationships between words in the text, forming a high-dimensional representation, often referred to as embeddings. So, you don't need to explicitly provide embeddings when using Gemini for text generation tasks.

## In summary, Gemini automatically handles the creation of embeddings as part of its internal processing when you provide text as input for generation. You only need to provide the input text, and Gemini takes care of the rest, including processing the text through its layers to generate meaningful responses.