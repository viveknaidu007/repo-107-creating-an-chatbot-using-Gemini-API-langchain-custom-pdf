{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: What is insulin therapy?\n",
      "A: Insulin therapy is essential for individuals with Type 1 diabetes and sometimes necessary for Type 2 diabetes. Insulin must be injected or used with an insulin pump.\n",
      "\n",
      "Q: Give dietary recommendations?\n",
      "A: Dietary recommendations include carbohydrate management, meal planning, and avoiding sugary foods.\n",
      "\n",
      "Extracted A1C value: 8.0\n",
      "Q: my A1C is 8 , do i have diabetes?\n",
      "A: Diabetes\n",
      "\n",
      "Extracted A1C value: 5.0\n",
      "Q: my A1C is 5 do i have diabetes?\n",
      "A: No Diabetes\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.schema import Document\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "import google.generativeai as genai\n",
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# Initialize Google Generative AI\n",
    "genai.configure(api_key=os.environ.get(\"GOOGLE_API_KEY\"))\n",
    "\n",
    "# Define the get_diabetes_level function\n",
    "def get_diabetes_level(a1c):\n",
    "    if a1c < 5.1:\n",
    "        return \"No Diabetes\"\n",
    "    elif 5.1 <= a1c < 7:\n",
    "        return \"Pre-Diabetes\"\n",
    "    elif a1c >= 7:\n",
    "        return \"Diabetes\"\n",
    "    else:\n",
    "        return \"Invalid A1C value\"\n",
    "\n",
    "# Initialize the ChatGoogleGenerativeAI model\n",
    "model = ChatGoogleGenerativeAI(model=\"gemini-pro\", temperature=0.3)\n",
    "\n",
    "# Load the PDF and extract text\n",
    "pdf_path = \"Basics of Diabetes Management.pdf\"\n",
    "pdf_loader = PyPDFLoader(pdf_path)\n",
    "pages = pdf_loader.load_and_split()\n",
    "\n",
    "# Create context from the first few pages of the PDF\n",
    "context = \"\\n\".join(page.page_content for page in pages[:30])\n",
    "\n",
    "# Define the prompt template\n",
    "prompt_template = \"\"\"\n",
    "You are a diabetes instructor. Answer the question as precisely as possible using the provided context. If the answer is\n",
    "not contained in the context, say \"answer not available in context\".\n",
    "\n",
    "Context: \\n{context}\\n\n",
    "Question: \\n{question}\\n\n",
    "Answer:\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(template=prompt_template, input_variables=[\"context\", \"question\"])\n",
    "\n",
    "# Manually set up the QA chain using LLMChain\n",
    "qa_chain = LLMChain(\n",
    "    llm=model,\n",
    "    prompt=prompt\n",
    ")\n",
    "\n",
    "# Function to chat with PDF\n",
    "def chat_with_pdf(question, context):\n",
    "    if \"A1C\" in question:\n",
    "        try:\n",
    "            # Extract the A1C value from the question by splitting and iterating over words\n",
    "            words = question.split()\n",
    "            for word in words:\n",
    "                if word.replace('.', '').isdigit():\n",
    "                    a1c_value = float(word)\n",
    "                    print(f\"Extracted A1C value: {a1c_value}\")\n",
    "                    return get_diabetes_level(a1c_value)\n",
    "            return \"A1C value not found in the question. Please provide a numerical value.\"\n",
    "        except ValueError:\n",
    "            return \"Invalid input for A1C value. Please provide a numerical value.\"\n",
    "    elif \"do i have diabetes\" in question:\n",
    "        # Extract the A1C value from the question\n",
    "        a1c_value_match = re.search(r\"(\\d+(\\.\\d+)?)\", question)\n",
    "        if a1c_value_match:\n",
    "            a1c_value = float(a1c_value_match.group(1))\n",
    "            diabetes_level = get_diabetes_level(a1c_value)\n",
    "            if diabetes_level == \"Diabetes\" or diabetes_level == \"Pre-Diabetes\":\n",
    "                return \"Yes, you have diabetes or pre-diabetes.\"\n",
    "            else:\n",
    "                return \"No, you don't have diabetes.\"\n",
    "        else:\n",
    "            return \"A1C value not found in the question. Please provide a numerical value.\"\n",
    "    else:\n",
    "        # Create Document object for the context\n",
    "        input_document = Document(page_content=context)\n",
    "        response = qa_chain(\n",
    "            {\"context\": context, \"question\": question}\n",
    "        )\n",
    "        return response['text']\n",
    "\n",
    "# Example questions\n",
    "questions = [\n",
    "    \"What is insulin therapy?\",\n",
    "    \"Give dietary recommendations?\",\n",
    "    \"my A1C is 8 , do i have diabetes?\",\n",
    "    \"my A1C is 5 do i have diabetes?\",\n",
    "]\n",
    "\n",
    "# Chat with PDF\n",
    "for question in questions:\n",
    "    answer = chat_with_pdf(question, context)\n",
    "    print(f\"Q: {question}\\nA: {answer}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#below code with user input chatbot "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: what is insulin\n",
      "A: Insulin is a hormone that helps the body use glucose for energy. It is essential for individuals with Type 1 diabetes and sometimes necessary for Type 2 diabetes.\n",
      "Q: what is diabetes\n",
      "A: Diabetes is a chronic condition characterized by high levels of glucose in the blood.\n",
      "Exiting...\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.schema import Document\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "import google.generativeai as genai\n",
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# Initialize Google Generative AI\n",
    "genai.configure(api_key=os.environ.get(\"GOOGLE_API_KEY\"))\n",
    "\n",
    "# Define the get_diabetes_level function\n",
    "def get_diabetes_level(a1c):\n",
    "    if a1c < 5.1:\n",
    "        return \"No Diabetes\"\n",
    "    elif 5.1 <= a1c < 7:\n",
    "        return \"Pre-Diabetes\"\n",
    "    elif a1c >= 7:\n",
    "        return \"Diabetes\"\n",
    "    else:\n",
    "        return \"Invalid A1C value\"\n",
    "\n",
    "# Initialize the ChatGoogleGenerativeAI model\n",
    "model = ChatGoogleGenerativeAI(model=\"gemini-pro\", temperature=0.3)\n",
    "\n",
    "# Load the PDF and extract text\n",
    "pdf_path = \"Basics of Diabetes Management.pdf\"\n",
    "pdf_loader = PyPDFLoader(pdf_path)\n",
    "pages = pdf_loader.load_and_split()\n",
    "\n",
    "# Create context from the first few pages of the PDF\n",
    "context = \"\\n\".join(page.page_content for page in pages[:30])\n",
    "\n",
    "# Define the prompt template\n",
    "prompt_template = \"\"\"\n",
    "You are a diabetes instructor. Answer the question as precisely as possible using the provided context. If the answer is\n",
    "not contained in the context, say \"answer not available in context\".\n",
    "\n",
    "Context: \\n{context}\\n\n",
    "Question: \\n{question}\\n\n",
    "Answer:\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(template=prompt_template, input_variables=[\"context\", \"question\"])\n",
    "\n",
    "# Manually set up the QA chain using LLMChain\n",
    "qa_chain = LLMChain(\n",
    "    llm=model,\n",
    "    prompt=prompt\n",
    ")\n",
    "\n",
    "# Function to chat with PDF\n",
    "def chat_with_pdf(question, context):\n",
    "    if \"A1C\" in question:\n",
    "        try:\n",
    "            # Extract the A1C value from the question by splitting and iterating over words\n",
    "            words = question.split()\n",
    "            for word in words:\n",
    "                if word.replace('.', '').isdigit():\n",
    "                    a1c_value = float(word)\n",
    "                    print(f\"Extracted A1C value: {a1c_value}\")\n",
    "                    return get_diabetes_level(a1c_value)\n",
    "            return \"A1C value not found in the question. Please provide a numerical value.\"\n",
    "        except ValueError:\n",
    "            return \"Invalid input for A1C value. Please provide a numerical value.\"\n",
    "    elif \"do i have diabetes\" in question:\n",
    "        # Extract the A1C value from the question\n",
    "        a1c_value_match = re.search(r\"(\\d+(\\.\\d+)?)\", question)\n",
    "        if a1c_value_match:\n",
    "            a1c_value = float(a1c_value_match.group(1))\n",
    "            diabetes_level = get_diabetes_level(a1c_value)\n",
    "            if diabetes_level == \"Diabetes\" or diabetes_level == \"Pre-Diabetes\":\n",
    "                return \"Yes, you have diabetes or pre-diabetes.\"\n",
    "            else:\n",
    "                return \"No, you don't have diabetes.\"\n",
    "        else:\n",
    "            return \"A1C value not found in the question. Please provide a numerical value.\"\n",
    "    else:\n",
    "        # Create Document object for the context\n",
    "        input_document = Document(page_content=context)\n",
    "        response = qa_chain(\n",
    "            {\"context\": context, \"question\": question}\n",
    "        )\n",
    "        return response['text']\n",
    "\n",
    "# Continuous interaction loop\n",
    "while True:\n",
    "    # Get user input\n",
    "    user_question = input(\"Ask a question (type 'exit' to quit): \")\n",
    "\n",
    "    # Check if user wants to exit\n",
    "    if user_question.lower() == 'exit':\n",
    "        print(\"Exiting...\")\n",
    "        break\n",
    "\n",
    "    # Get answer using LLM\n",
    "    answer = chat_with_pdf(user_question, context)\n",
    "    print(\"Q:\", user_question)\n",
    "    print(\"A:\", answer)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dlproj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
